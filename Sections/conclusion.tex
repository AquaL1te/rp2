% \section{Conclusion}\label{conc}
% In this research we presented a design for sharing digital objects using \gls{ndn} with support for multiple \gls{pid} providers. Our findings give insight for distributed infrastructures that manage large and diverse sets of data such as SeaDataCloud and CS3.

% Initially, we started researching the state of the art technologies for creating our design. We came to the conclusion that \gls{ndn} would fit the technical challenges we had to work out.
% After, we started researching \gls{pid} interoperability with the \gls{ndn} namespace and found out that our principles can be adhered as discussed in section \ref{pid-poc}. Metadata can be parsed to fill in possible naming gaps in an \gls{ndn} name and the \gls{ndn} namespace is unbounded. However long \gls{ndn} names have to be taken in account, as that can degrade performance.
% As discussed in section \ref{planning-ndn}, we proved that our solution achieves flexible scaling and planning of an \gls{ndn} network by managing the \gls{ndn} infrastructure with Kubernetes.
% We concluded that a scalable and manageable data distribution network can be realized by using a VNF-style of an \gls{ndn} deployment.
% Finally, we discuss preliminary performance measurements. Our results show that \gls{ndn} over TCP gives the best performance, which correlates with previous work.

%TO-DO: extending the second part of the conclusion if needed.
%We simulated the use of \gls{tosca} with an orchestrator like \gls{drip} by using the YAML configuration of Kuberenetes which acts as a \gls{tosca} template and the processing of this template
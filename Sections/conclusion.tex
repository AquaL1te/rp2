\section{Conclusion}\label{conc}
In this research we present a design for sharing digital objects using NDN with support for multiple PID providers. Our findings give insight for distributed infrastructures that manage large and diverse sets of data like SeaDataCloud and CS3. 

Initially, we started researching the state of the art technologies for creating our design. After, we discuss the methods for used for our design. The first method manages to achieve PID interoperability of different PID types with the NDN namespace. While the second method covers planning and scaling of an NDN network. 

The first method in section \ref{pid-poc} showed that our principles regarding PID interoperability with the NDN namespace can be adhered. Metadata can be parsed to fill in possible naming gaps in an NDN name. However long NDN names have to be taken in account, as that can degrade performance. 
%Translation of PIDs to an NDN name can be made transparent to the user, as the gateway is responsible for the translation and the client takes care of object retrieval either from the PID provider or from the NDN network.
Our solution is designed to be extensible, new PID schemas can be added at the gateway. Therefore, only the gateway needs to update its PID support in our design. The client is agnostic towards PID types, it is up to the gateway to verify the types and send an appropriate response. This elevates the burden of updating client software.

The second method in section \ref{planning-ndn} achieves flexible scaling and planning of an NDN network by managing the NDN infrastructure with Kubernetes. We have demonstrated a method for scaling in or out the NDN application, despite lacking a orchestrator like DRIP to demonstrate scaling in or out resources to other cloud providers with TOSCA. Our method allows to reconfigure an NDN infrastructure 
by interacting with Kubernetes as the orchestrator.
%Mention TOSCA again and that we conclude that TOSCA can be used.
We concluded that a scalable and manageable data distribution network can be realized by using a VNF-style of an NDN deployment. 

Finally, we discuss preliminary performance measurements. Our results show that NDN over TCP gives the best performance, which correlate with previous work.

%This research investigated sharing digital objects using NDN, where we achieved PID interoperability of different PID types with the NDN namespace and planning and scaling of such an NDN network. 
%Our findings give insight for distributed infrastructures that manage large and diverse sets of data like SeaDataCloud and CS3. We 

%explain why NDN networking should be chosen for retrieving digital objects instead of host-to-host communications.

%The implementation of our design in a proof of concept shows that our principles regarding PID interoperability with the NDN namespace can be adhered. The translation of PIDs to an NDN name can be made transparent to the user, as the gateway is responsible for the translation and the client takes care of object retrieval either from the PID provider or from the NDN network. Only a PID should be needed from the user input. Translation is achieved by first recognizing the PID type based on pattern matching and then hierarchically divide the PID to an NDN name. 

%Our solution is designed to be extensible, new PID schemas can be added at the gateway. Therefore, only the gateway needs to update its PID support. The client is agnostic towards PID types, it is up to the gateway to verify the types and send an appropriate response. This elevates the burden of updating client software.

%Support for multiple PID types is also realized by adding the schema of the PID types at the gateway, which makes it also easily extensible to support future PID types. Adding PID types at the gateway overcomes the hurdle of updating the client side with the schema of the new PID type each time when a new PID type is introduced.

%We achieved flexible scaling and planning of an NDN network by managing the NDN infrastructure with Kubernetes. We have demonstrated a method for scaling in or out the NDN application, despite lacking a orchestrator like DRIP to demonstrate scaling in or out resources to other cloud providers with TOSCA. Our method allows to reconfigure an NDN infrastructure by interacting with Kubernetes as the orchestrator. The YAML configuration of Kubernetes can be seen as the TOSCA template description which is processed by Kubernetes, which in turn acts as an orchestrator instead of DRIP.